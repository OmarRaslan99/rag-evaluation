# RAG Evaluate

Un projet de dÃ©monstration pour tester la bibliothÃ¨que **RAGAS**  
Il permet de gÃ©rer des contextes, questions et rÃ©ponses, ainsi que dâ€™Ã©valuer un pipeline Retrieval-Augmented Generation.

---

## ğŸ“‹ TODOs

1. âœ… **POC basique**  
   - CrÃ©ation dâ€™un POC utilisant RAGAS avec des contextes, questions et rÃ©ponses codÃ©s en dur  
   - Fichier : `main_v1.py`

2. âœ… **Chunking de PDF**  
   - GÃ©nÃ©ration de chunks Ã  partir dâ€™un document PDF  
   - Affichage des chunks  
   - Fichier : `main_v2.py`

3. ğŸ”„ **Construction du dataset**  
   - Ã€ partir des chunks (colonne `contextes`)  
   - GÃ©nÃ©ration automatique des colonnes `questions` et `rÃ©ponses` via LLM  
   - **Statut** : en cours

4. ğŸ”œ **Ã‰valuation avec RAGAS**  
   - Appliquer les outils dâ€™Ã©valuation de RAGAS sur la base de donnÃ©es gÃ©nÃ©rÃ©e  
   - **Statut** : Ã  faire

5. ğŸ”œ **Optimisation du chunking**  
   - Une fois le dataset validÃ©, expÃ©rimenter dâ€™autres mÃ©thodes de dÃ©coupage  
   - **Statut** : Ã  faire

---